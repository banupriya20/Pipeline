# Pipeline
For Repository
-questions
**** -how did you test your pipelines?****
     I have tested my pipeline manually first ,by running each pipeline job in a staging environment and ensure that build steps completed successfully and manully verified the generated ouput file and the CSV file contain the expected data and the syntax of the files was tested using the visual studio code by having dedugger for it
    we can use unit testing&junit testing and continuous intergation to test the pipeline code 
    we can do unit testing through jenkins pipeline unit library 
    And for jnuit we can junit pulgin for java based project and generate the junit.report.xml

**** -how did you test RepoC python?****
     To test this code, I have created a test file with some test cases that exercise the parse_doxygen_warnings_log and write_csv_file functions with some sample input and check if the output matches the expected output. It involved by creating a sample warnings.log file and comparing the output CSV file generated by the code.I did debug this visual stuido code and tested this as well.
    I also might consider using a testing framework such as unittest to organize and automate tests.This frameworks provide utilities for running tests, reporting on their results, and handling any failures or errors.
-repoA-doc contains binaries
**-what is the advantages to use LFS?**
   Since github has limit of pushing large file to if we want to push the large file to repo we use git lfs.
Suppose we create a 100gb repository which means that each clone will download 100gb of data,eat 10gb of disk space on each machine on which we are making the clone.Putting these big files in a separate system like git-lfs allow you to store only pointors to each version of the file of the repository hence each clone will only download a tiny piece of data for each version
For example, Artifact in pipelineB is a binary file and git tracking of the file is not possible,but using LFS it would be possible to track the file as normal git file
**** -how to adjust this repository to support LFS?****
   -Install the LFS extension on git
   -modify the newly created .gitattributes in root of the repository to include the file patterns that LFS should track 

      git lfs install
      git lfs track "*.tar.gz"
      git add .gitattributes
      git commit -m "add .gitattributes"
      git push origin main
   -Now when the file matches the pattern is pushed, LFS will takecare of storing the binary files
